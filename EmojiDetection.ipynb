{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EmojiDetection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1fSxKddd_aJXIIZ-4YdmS2GkQA3KLs1oI","authorship_tag":"ABX9TyPu79RE36essDqELafgcFMO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wj58BDYMTI0b","executionInfo":{"status":"ok","timestamp":1659449232375,"user_tz":-330,"elapsed":25824,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"b7eff053-3802-4996-bace-2ec56305de1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-2.0.0.tar.gz (197 kB)\n","\u001b[K     |████████████████████████████████| 197 kB 5.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193022 sha256=86cefb2cbe4947bfbcc1736913836c8a67b09321339ba12e7a0359c14931ba88\n","  Stored in directory: /root/.cache/pip/wheels/ec/29/4d/3cfe7452ac7d8d83b1930f8a6205c3c9649b24e80f9029fc38\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Imported Successfully!\n"]}],"source":["!pip install emoji\n","!pip install numpy\n","!pip install pandas\n","!pip install keras\n","\n","import numpy as np\n","import pandas as pd\n","import emoji as emoji\n","print('Imported Successfully!')"]},{"cell_type":"code","source":["#print(emoji.EMOJI_UNICODE)\n","#print(len(emoji.EMOJI_UNICODE))\n","emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n","                    \"1\": \":baseball:\",\n","                    \"2\": \":beaming_face_with_smiling_eyes:\",\n","                    \"3\": \":downcast_face_with_sweat:\",\n","                    \"4\": \":fork_and_knife:\",\n","                   }\n","for e in emoji_dictionary.values():\n","  print(emoji.emojize(e))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_R1j7qtTesC","executionInfo":{"status":"ok","timestamp":1659449241614,"user_tz":-330,"elapsed":334,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"e31ccd5c-091e-4654-9412-4d975ab466d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["❤️\n","⚾\n","😁\n","😓\n","🍴\n"]}]},{"cell_type":"code","source":["# Load the Training and Testing dataset\n","import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/Tutorials/Homework/LSTM/train_emoji.csv',header=None)\n","test = pd.read_csv('/content/drive/MyDrive/Tutorials/Homework/LSTM/test_emoji.csv',header=None)\n","data = train.values\n","for i in range(10):\n","    val=str(data[i][1])\n","    print(data[i][0],emoji.emojize(emoji_dictionary[val]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WE5Mf8ETxOz","executionInfo":{"status":"ok","timestamp":1659450131397,"user_tz":-330,"elapsed":462,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"51a05207-f53c-4e81-c089-088c44b96f14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["never talk to me again 😓\n","I am proud of your achievements 😁\n","It is the worst day in my life 😓\n","Miss you so much ❤️\n","food is life 🍴\n","I love you mum ❤️\n","Stop saying bullshit 😓\n","congratulations on your acceptance 😁\n","The assignment is too long  😓\n","I want to go play ⚾\n"]}]},{"cell_type":"code","source":["#Load GLOVE Embeddings\n","!wget  \"http://nlp.stanford.edu/data/glove.6B.zip\"\n","!unzip \"glove.6B.zip\"\n","embeddings = {}\n","with open('glove.6B.50d.txt',encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coeffs = np.asarray(values[1:],dtype='float32')\n","        embeddings[word] = coeffs\n","\n","print(embeddings['eat'])\n","print(embeddings['play'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kd2lhMUUaxx","executionInfo":{"status":"ok","timestamp":1659450342653,"user_tz":-330,"elapsed":189882,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"558dcd67-6ce4-4d73-94fa-71a87f2dfc7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-02 14:22:32--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2022-08-02 14:22:32--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2022-08-02 14:22:32--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n","\n","2022-08-02 14:25:12 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n","[ 6.4295e-01 -4.2946e-01 -5.4277e-01 -1.0307e+00  1.2056e+00 -2.7174e-01\n"," -6.3561e-01 -1.5065e-02  3.7856e-01  4.6474e-02 -1.3102e-01  6.0500e-01\n","  1.6391e+00  2.3940e-01  1.2128e+00  8.3178e-01  7.3893e-01  1.5200e-01\n"," -1.4175e-01 -8.8384e-01  2.0829e-02 -3.2545e-01  1.8035e+00  1.0045e+00\n","  5.8484e-01 -6.2031e-01 -4.3296e-01  2.3562e-01  1.3027e+00 -8.1264e-01\n","  2.3158e+00  1.1030e+00 -6.0608e-01  1.0101e+00 -2.2426e-01  1.8908e-02\n"," -1.0931e-01  3.8350e-01  7.7362e-01 -8.1927e-02 -3.4040e-01 -1.5143e-03\n"," -5.6640e-02  8.7359e-01  1.4805e+00  6.9421e-01 -3.0966e-01 -9.0826e-01\n","  3.7277e-03  8.4550e-01]\n","[-0.73571   0.19937  -0.89408   0.36406  -0.20246  -0.034324 -0.63138\n","  0.76669  -0.94343   0.65883   0.049478  0.55608  -1.2809    0.44575\n","  0.73791   0.014728  0.80956  -0.35516  -1.0248   -0.13845  -0.47632\n","  0.32001   0.35023   0.77794   0.60233  -1.2321    0.043144 -0.41347\n","  0.34533  -1.3093    3.4681    0.9882    0.038253 -0.33672   0.30999\n","  0.6331    0.30798   0.68528  -0.21989  -0.77505  -0.036884  0.051738\n"," -0.25442  -0.063405 -0.20665   0.91281   0.80133  -0.075279 -0.44448\n","  0.47437 ]\n"]}]},{"cell_type":"code","source":["import tensorflow\n","import keras \n","from tensorflow.keras.utils import to_categorical\n","XT = train[0]\n","Xt = test[0]\n","\n","YT = to_categorical(train[1])\n","Yt = to_categorical(test[1])\n","\n","\n","print(XT.shape)\n","print(Xt.shape)\n","print(YT.shape)\n","print(Yt.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlLu_FVMVPBb","executionInfo":{"status":"ok","timestamp":1659450345200,"user_tz":-330,"elapsed":2557,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"3994e3ef-e520-4c84-a749-54d85e173e96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(132,)\n","(56,)\n","(132, 5)\n","(56, 5)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"hXfh2ycSmghZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get Output Embeddings\n","def getOutputEmbeddings(X):\n","    \n","    embedding_matrix_output = np.zeros((X.shape[0],10,50))\n","    for ix in range(X.shape[0]):\n","        X[ix] = X[ix].split()\n","        for jx in range(len(X[ix])):\n","            embedding_matrix_output[ix][jx] = embeddings[X[ix][jx].lower()]\n","            \n","    return embedding_matrix_output\n","\n","emb_XT = getOutputEmbeddings(XT)\n","emb_Xt = getOutputEmbeddings(Xt)\n","print(emb_XT.shape)\n","print(emb_Xt.shape)\n","print(emb_XT[1])"],"metadata":{"id":"Dr9dQMijVXJN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659450345201,"user_tz":-330,"elapsed":5,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"60c03f75-679c-4fc9-d0ec-78264c457d3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(132, 10, 50)\n","(56, 10, 50)\n","[[ 1.18910000e-01  1.52549997e-01 -8.20730031e-02 -7.41439998e-01\n","   7.59169996e-01 -4.83280003e-01 -3.10090005e-01  5.14760017e-01\n","  -9.87079978e-01  6.17570011e-04 -1.50429994e-01  8.37700009e-01\n","  -1.07969999e+00 -5.14599979e-01  1.31879997e+00  6.20069981e-01\n","   1.37789994e-01  4.71080005e-01 -7.28740022e-02 -7.26750016e-01\n","  -7.41159976e-01  7.52629995e-01  8.81799996e-01  2.95610011e-01\n","   1.35479999e+00 -2.57010007e+00 -1.35230005e+00  4.58799988e-01\n","   1.00680006e+00 -1.18560004e+00  3.47370005e+00  7.78980017e-01\n","  -7.29290009e-01  2.51020014e-01 -2.61559993e-01 -3.46839994e-01\n","   5.58409989e-01  7.50980020e-01  4.98299986e-01 -2.68229991e-01\n","  -2.74430006e-03 -1.82980001e-02 -2.80959994e-01  5.53179979e-01\n","   3.77059989e-02  1.85550004e-01 -1.50250003e-01 -5.75119972e-01\n","  -2.66710013e-01  9.21209991e-01]\n"," [ 3.46639991e-01  3.98050010e-01  4.89699990e-01 -5.14209986e-01\n","   5.45740008e-01 -1.20050001e+00  3.21069986e-01  7.40040004e-01\n","  -1.49790001e+00 -1.96510002e-01 -1.26310006e-01 -3.77029985e-01\n","  -6.25689983e-01  3.87919992e-02  1.05789995e+00  7.71990001e-01\n","  -1.85890004e-01  1.30320001e+00 -7.21279979e-01  4.02310014e-01\n","   6.64419979e-02  1.23150003e+00  9.39559996e-01  1.39030004e+00\n","   1.53340006e+00 -1.47300005e+00 -3.49970013e-01  3.15620005e-01\n","   9.06910002e-01  4.54979986e-01  2.54809999e+00  1.64100006e-01\n","  -6.06999993e-01  2.70610005e-01 -7.90719986e-01 -1.14600003e+00\n","   9.17949975e-01 -1.17969997e-01  2.35259995e-01 -1.26589999e-01\n","   6.65269971e-01 -9.18160021e-01  1.00479998e-01  7.04569995e-01\n","  -2.17769995e-01  5.24789989e-01 -5.44520020e-01  8.65759999e-02\n","   3.40369999e-01  1.35880005e+00]\n"," [-5.91799974e-01  2.76710004e-01 -4.69709992e-01 -5.47429979e-01\n","   1.35039997e+00 -6.39069974e-01 -6.81900024e-01  5.42069972e-01\n","  -4.05519992e-01  1.12709999e-01  1.56399995e-01  2.16040000e-01\n","  -3.50730009e-02 -3.02280009e-01  1.57529995e-01 -1.04369998e-01\n","   6.45609975e-01  1.08430004e+00  2.87880003e-01 -2.40309998e-01\n","  -1.28929996e+00  8.29490006e-01 -4.45470005e-01  1.10849999e-01\n","   1.12489998e+00 -1.54740000e+00 -1.39670002e+00  1.39300004e-01\n","   2.31330007e-01 -4.69740003e-01  1.58290005e+00  8.70949984e-01\n","   1.36449993e-01  4.74609993e-02 -3.79139990e-01 -4.56079990e-01\n","   3.31729986e-02  3.94430012e-01 -6.71859980e-01 -9.27649975e-01\n","  -1.90479994e-01 -5.94410002e-01 -4.63909991e-02  1.40509993e-01\n","   3.28629985e-02  4.28130001e-01 -1.38880002e+00 -2.00550005e-01\n","  -2.64869988e-01  5.79810023e-01]\n"," [ 7.08530009e-01  5.70879996e-01 -4.71599996e-01  1.80480003e-01\n","   5.44489980e-01  7.26029992e-01  1.81569993e-01 -5.23930013e-01\n","   1.03809997e-01 -1.75659999e-01  7.88519979e-02 -3.62159997e-01\n","  -1.18290000e-01 -8.33360016e-01  1.19170003e-01 -1.66050002e-01\n","   6.15549982e-02 -1.27189998e-02 -5.66229999e-01  1.36160003e-02\n","   2.28510007e-01 -1.43959999e-01 -6.75489977e-02 -3.81570011e-01\n","  -2.36980006e-01 -1.70369995e+00 -8.66919994e-01 -2.67040014e-01\n","  -2.58899987e-01  1.76699996e-01  3.86759996e+00 -1.61300004e-01\n","  -1.32730007e-01 -6.88809991e-01  1.84440002e-01  5.24639990e-03\n","  -3.38739991e-01 -7.89560005e-02  2.41850004e-01  3.65759999e-01\n","  -3.47270012e-01  2.84830004e-01  7.56929964e-02 -6.21780008e-02\n","  -3.89880002e-01  2.29020000e-01 -2.16169998e-01 -2.25620002e-01\n","  -9.39180031e-02 -8.03749979e-01]\n"," [-2.91629992e-02  8.17690015e-01  3.84700000e-01 -7.78569996e-01\n","   1.10490000e+00 -1.36549994e-01 -2.46910006e-02 -5.11029996e-02\n","   7.79500008e-01  5.13570011e-02 -3.57479990e-01  1.17480004e+00\n","  -9.82439965e-02  3.31110001e-01  4.04260010e-01  5.86849988e-01\n","  -6.25360012e-01  9.48330015e-02  9.70239997e-01 -1.14370000e+00\n","   1.38260007e-01  2.81360000e-01  4.66930002e-01  3.52259994e-01\n","   6.89159989e-01 -1.98189998e+00 -1.39999998e+00  1.70010000e-01\n","   1.59290004e+00 -1.00860000e+00  3.64989996e+00  1.39489996e+00\n","  -7.88230002e-01  4.04040009e-01 -3.69250000e-01  7.30750024e-01\n","   2.75129993e-02 -1.19929999e-01  7.37160027e-01 -1.03649998e+00\n","   6.86590016e-01 -3.02940011e-01 -5.51750004e-01  9.64659989e-01\n","   5.31029999e-02 -8.48070011e-02  8.51199985e-01 -5.41859984e-01\n","   3.24530005e-01  5.84249973e-01]\n"," [-5.19330025e-01  1.36679995e+00 -6.87399983e-01  9.52199996e-02\n","   1.86069995e-01 -3.33860010e-01 -5.01290001e-02 -4.02980000e-01\n","   3.33730012e-01  6.52249992e-01  7.14410022e-02  1.30549997e-01\n","  -4.43859994e-01 -5.17090023e-01 -2.66069993e-02 -8.69610012e-01\n","   3.77290010e-01  2.45729998e-01  5.71489990e-01 -1.00950003e-01\n","  -2.45479997e-02  3.23060006e-02 -3.17290008e-01 -1.58720005e+00\n","   1.10990000e+00 -5.70500016e-01 -1.46039999e+00 -7.85910010e-01\n","  -7.24409997e-01  2.78990000e-01  2.12669992e+00  1.07620001e+00\n","   2.75050014e-01 -1.26479995e+00 -7.47049972e-02  4.62799996e-01\n","  -3.60339999e-01  1.24660003e+00 -1.31649995e+00 -4.15159985e-02\n","  -9.77469981e-01 -6.49179995e-01 -2.82469988e-01 -3.49090010e-01\n","  -5.05079985e-01  1.92450006e-02 -4.96300012e-01  1.05449998e+00\n","  -1.94040000e-01 -7.09510028e-01]\n"," [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00]\n"," [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00]\n"," [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00]\n"," [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","   0.00000000e+00  0.00000000e+00]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n"]}]},{"cell_type":"code","source":["#Create LSTM Model\n","from keras.layers import *\n","from keras.models import Sequential\n","\n","model = Sequential()\n","model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n","model.add(Dropout(0.4))\n","model.add(LSTM(64,input_shape=(10,50)))\n","model.add(Dropout(0.3))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))\n","model.summary()\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n","model.fit(emb_XT,YT,batch_size=32,epochs=40,shuffle=True,validation_split=0.1)\n","model.evaluate(emb_Xt,Yt)"],"metadata":{"id":"aMTE_OyWVkHf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659450354686,"user_tz":-330,"elapsed":9488,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"b7f72306-fb08-4b5f-b311-0836e126c894"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 10, 64)            29440     \n","                                                                 \n"," dropout (Dropout)           (None, 10, 64)            0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 5)                 325       \n","                                                                 \n"," activation (Activation)     (None, 5)                 0         \n","                                                                 \n","=================================================================\n","Total params: 62,789\n","Trainable params: 62,789\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/40\n","4/4 [==============================] - 5s 310ms/step - loss: 1.6118 - acc: 0.2119 - val_loss: 1.6149 - val_acc: 0.0714\n","Epoch 2/40\n","4/4 [==============================] - 0s 24ms/step - loss: 1.5445 - acc: 0.3136 - val_loss: 1.6213 - val_acc: 0.1429\n","Epoch 3/40\n","4/4 [==============================] - 0s 22ms/step - loss: 1.5061 - acc: 0.3898 - val_loss: 1.6216 - val_acc: 0.2857\n","Epoch 4/40\n","4/4 [==============================] - 0s 21ms/step - loss: 1.4608 - acc: 0.3559 - val_loss: 1.6160 - val_acc: 0.2857\n","Epoch 5/40\n","4/4 [==============================] - 0s 21ms/step - loss: 1.4211 - acc: 0.4068 - val_loss: 1.5931 - val_acc: 0.1429\n","Epoch 6/40\n","4/4 [==============================] - 0s 21ms/step - loss: 1.3583 - acc: 0.4322 - val_loss: 1.5510 - val_acc: 0.0714\n","Epoch 7/40\n","4/4 [==============================] - 0s 20ms/step - loss: 1.3024 - acc: 0.4746 - val_loss: 1.4418 - val_acc: 0.2143\n","Epoch 8/40\n","4/4 [==============================] - 0s 22ms/step - loss: 1.1826 - acc: 0.6356 - val_loss: 1.3411 - val_acc: 0.3571\n","Epoch 9/40\n","4/4 [==============================] - 0s 20ms/step - loss: 1.0711 - acc: 0.6186 - val_loss: 1.3929 - val_acc: 0.3571\n","Epoch 10/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.9544 - acc: 0.7119 - val_loss: 1.2019 - val_acc: 0.4286\n","Epoch 11/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.8314 - acc: 0.7373 - val_loss: 1.1229 - val_acc: 0.5714\n","Epoch 12/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.7199 - acc: 0.7797 - val_loss: 0.9647 - val_acc: 0.5714\n","Epoch 13/40\n","4/4 [==============================] - 0s 22ms/step - loss: 0.6747 - acc: 0.7881 - val_loss: 1.0922 - val_acc: 0.5714\n","Epoch 14/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.6296 - acc: 0.8136 - val_loss: 0.8297 - val_acc: 0.6429\n","Epoch 15/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.5311 - acc: 0.8475 - val_loss: 1.2420 - val_acc: 0.5000\n","Epoch 16/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.5237 - acc: 0.8051 - val_loss: 0.8723 - val_acc: 0.6429\n","Epoch 17/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.4414 - acc: 0.8644 - val_loss: 0.7804 - val_acc: 0.6429\n","Epoch 18/40\n","4/4 [==============================] - 0s 24ms/step - loss: 0.3976 - acc: 0.8898 - val_loss: 1.4993 - val_acc: 0.4286\n","Epoch 19/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.5243 - acc: 0.8305 - val_loss: 0.8487 - val_acc: 0.7143\n","Epoch 20/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.3654 - acc: 0.8644 - val_loss: 0.5398 - val_acc: 0.7143\n","Epoch 21/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.2843 - acc: 0.9237 - val_loss: 0.7623 - val_acc: 0.6429\n","Epoch 22/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.2821 - acc: 0.9322 - val_loss: 0.7159 - val_acc: 0.5714\n","Epoch 23/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.2702 - acc: 0.8983 - val_loss: 0.6709 - val_acc: 0.7143\n","Epoch 24/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.2422 - acc: 0.9237 - val_loss: 0.6327 - val_acc: 0.6429\n","Epoch 25/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.2288 - acc: 0.9407 - val_loss: 0.7522 - val_acc: 0.6429\n","Epoch 26/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.2184 - acc: 0.9237 - val_loss: 1.0734 - val_acc: 0.5714\n","Epoch 27/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.2316 - acc: 0.9322 - val_loss: 0.8273 - val_acc: 0.5714\n","Epoch 28/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.1310 - acc: 0.9746 - val_loss: 1.1332 - val_acc: 0.6429\n","Epoch 29/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.1869 - acc: 0.9407 - val_loss: 0.9968 - val_acc: 0.5714\n","Epoch 30/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.1626 - acc: 0.9322 - val_loss: 0.8188 - val_acc: 0.6429\n","Epoch 31/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.1550 - acc: 0.9746 - val_loss: 1.3176 - val_acc: 0.6429\n","Epoch 32/40\n","4/4 [==============================] - 0s 26ms/step - loss: 0.1797 - acc: 0.9492 - val_loss: 0.6122 - val_acc: 0.6429\n","Epoch 33/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.1821 - acc: 0.9407 - val_loss: 0.5530 - val_acc: 0.7857\n","Epoch 34/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.1505 - acc: 0.9322 - val_loss: 1.3328 - val_acc: 0.4286\n","Epoch 35/40\n","4/4 [==============================] - 0s 24ms/step - loss: 0.1570 - acc: 0.9407 - val_loss: 0.8029 - val_acc: 0.6429\n","Epoch 36/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.1345 - acc: 0.9407 - val_loss: 0.8397 - val_acc: 0.6429\n","Epoch 37/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.1048 - acc: 0.9746 - val_loss: 1.1200 - val_acc: 0.5000\n","Epoch 38/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.0788 - acc: 0.9915 - val_loss: 0.8881 - val_acc: 0.6429\n","Epoch 39/40\n","4/4 [==============================] - 0s 21ms/step - loss: 0.0785 - acc: 0.9831 - val_loss: 0.6785 - val_acc: 0.7143\n","Epoch 40/40\n","4/4 [==============================] - 0s 20ms/step - loss: 0.0924 - acc: 0.9831 - val_loss: 1.2442 - val_acc: 0.5714\n","2/2 [==============================] - 0s 10ms/step - loss: 1.4256 - acc: 0.6250\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.425560712814331, 0.625]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#Predict the results\n","#pred = model.predict_classes(emb_Xt)\n","predict_x=model.predict(emb_Xt) \n","classes_x=np.argmax(predict_x,axis=1)\n","for i in range(5):\n","    print(''.join(Xt[i]))\n","    print(emoji.emojize(emoji_dictionary[str(np.argmax(Yt[i]))]))\n","    print(emoji.emojize(emoji_dictionary[str(classes_x[i])]))"],"metadata":{"id":"qa7mDRC_VwNv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659450369338,"user_tz":-330,"elapsed":852,"user":{"displayName":"Asha S","userId":"04893217347720392044"}},"outputId":"29dc2d0a-9dff-47b2-ba78-7159d6e8d30f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iwanttoeat\n","🍴\n","🍴\n","hedidnotanswer\n","😓\n","😓\n","hegotaraise\n","😁\n","😓\n","shegotmeapresent\n","❤️\n","😁\n","hahahaitwassofunny\n","😁\n","😁\n"]}]},{"cell_type":"markdown","source":["In case you want to use BERT embeddings, sample code is here: https://www.analyticsvidhya.com/blog/2021/12/text-classification-using-bert-and-tensorflow/ "],"metadata":{"id":"i0KyCL-MYgXc"}}]}